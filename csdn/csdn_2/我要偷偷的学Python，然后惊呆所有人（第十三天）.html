
<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Document</title>

</head>
<body>
    <article class="baidu_pl">
        <div id="article_content" class="article_content clearfix">
        <link rel="stylesheet" href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/ck_htmledit_views-b5506197d8.css">
                <div id="content_views" class="markdown_views prism-atom-one-light">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <p><img src="https://img-blog.csdnimg.cn/2020102316024217.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzYyMTkx,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> 
<blockquote> 
 <p>标题无意冒犯，就是觉得这个广告挺好玩的<br> 上面这张思维导图喜欢就拿走，反正我也学不了这么多</p> 
</blockquote> 
<p></p>
<div class="toc">
 <h3>文章目录</h3>
 <ul><li><ul><li><a href="#_8">前言</a></li><li><ul><li><a href="#_19">欢迎来到我们的圈子</a></li></ul>
   </li><li><a href="#scrapy_38">安装scrapy</a></li><li><a href="#scrapy_79">什么是scrapy</a></li><li><a href="#scrapy_87">scrapy架构</a></li><li><a href="#pycharmscrapy_139">pycharm体验scrapy项目</a></li><li><ul><li><a href="#scrapy_140">天才第一步：创建scrapy项目</a></li><li><a href="#items_162">天才第二步：明确目标，构建items</a></li><li><a href="#_182">制作爬虫</a></li><li><a href="#_251">取数据</a></li></ul>
  </li></ul>
 </li></ul>
</div>
<p></p> 
<h2><a id="_8"></a>前言</h2> 
<p>前期回顾：<a href="https://lion-wu.blog.csdn.net/article/details/109766564">我要偷偷学Python（第十二天）</a></p> 
<p>第十二篇的项目还在持续更新中，哎，日理万机虽然谈不上，但是也是手忙脚乱。这不，自动表单生成是写完了，但是学校网络实在是受不了啊，2G，测试不了，就只能一直搁置在那边了。<br> 明天就可以去测试了，明天出学校去逛逛。</p> 
<p>今天讲scrapy框架，有不少小伙伴问我说为什么最近没更新，实在是这个不好办呐，安装上就花了些功夫嘞，不过你们跟着我的安装步骤，就不用走那么多的弯路了。</p> 
<p>插播一条推送：（如果是小白的话，可以看一下下面这一段）</p> 
<h3><a id="_19"></a>欢迎来到我们的圈子</h3> 
<p>我建了一个Python学习答疑群，有兴趣的朋友可以了解一下：<a href="https://editor.csdn.net/md/?articleId=109220943">这是个什么群</a></p> 
<p>群里已经有一千三百多个小伙伴了哦！！！</p> 
<p>直通群的传送门：<a href="https://jq.qq.com/?_wv=1027&amp;k=uU1Wqnqe">传送门</a></p> 
<hr> 
<pre><code class="prism language-python">本系列文默认各位有一定的C或C<span class="token operator">+</span><span class="token operator">+</span>基础，因为我是学了点C<span class="token operator">+</span><span class="token operator">+</span>的皮毛之后入手的Python，这里也要感谢齐锋学长送来的支持。
本系列文默认各位会百度，学习‘模块’这个模块的话，还是建议大家有自己的编辑器和编译器的，上一篇已经给大家做了推荐啦？

我要的不多，点个关注就好啦
然后呢，本系列的目录嘛，说实话我个人比较倾向于那两本 Primer Plus，所以就跟着它们的目录结构吧。

本系列也会着重培养各位的自主动手能力，毕竟我不可能把所有知识点都给你讲到，所以自己解决需求的能力就尤为重要，所以我在文中埋得坑请不要把它们看成坑，那是我留给你们的锻炼机会，请各显神通，自行解决。
</code></pre> 
<h2><a id="scrapy_38"></a>安装scrapy</h2> 
<p>这里我并不打算说我安装过程中踩了多少坑，反正你现在跟着我来做：</p> 
<p>1、win+R，cmd，打开终端<br> 2、</p> 
<pre><code class="prism language-python">pip install pywin32
pip install pyopenssl
pip install wheel
</code></pre> 
<p>3、打开https://www.lfd.uci.edu/~gohlke/pythonlibs/，找到twisted和lxml两个whl文件，下载下来。</p> 
<p>4、进入两个文件的存放目录下，</p> 
<pre><code class="prism language-python">pip install Twisted·····
pip install lxml····
</code></pre> 
<p>5、安装scrapy，这里需要引入国内源。</p> 
<pre><code class="prism language-python">pip install Scrapy <span class="token operator">-</span>i https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>tuna<span class="token punctuation">.</span>tsinghua<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">/</span>simple
</code></pre> 
<p>整完之后速度嗖嗖的。</p> 
<p>好，当它显示给你说success，就万事大吉了吗？并不是这样的。<br> 这里你需要做两件事情：<br> 1、先弄清楚你安装在了那个Python上，如果你的电脑上只有一个Python就零担别论了，像我的电脑上就有三个Python。<br> 这时候：终端输入：python --version，就可以看到Python的版本号了。<br> 2、在新建文件的时候，<br> <img src="https://img-blog.csdnimg.cn/20201116200206293.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzYyMTkx,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> 
<p>好极，这样就解决了pycharm上有些包无法安装的问题，以及有些包不翻墙解决不了的问题。</p> 
<p>好，我们开始今天的主题：Scrapy。</p> 
<h2><a id="scrapy_79"></a>什么是scrapy</h2> 
<p>Scrapy，Python开发的一个快速、高层次的屏幕抓取和web抓取框架，用于抓取web站点并从页面中提取结构化的数据。Scrapy用途广泛，可以用于数据挖掘、监测和自动化测试.</p> 
<p>牛顿说，他只是站在了巨人的肩膀上。说真的，作为一个学C++过来的人，我还没有体验过框架的力量，听说框架可以定制功能，我们只需要将我们所需要的主要功能填充进去，便可以快速的得到我们想要的效果，就像把不同的光碟，插入DVD。</p> 
<p>Scrapy吸引人的地方在于它是一个框架，任何人都可以根据需求方便的修改。它也提供了多种类型爬虫的基类，如BaseSpider、sitemap爬虫等，最新版本又提供了web2.0爬虫的支持。</p> 
<h2><a id="scrapy_87"></a>scrapy架构</h2> 
<p><img src="https://img-blog.csdnimg.cn/2020111620243254.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzYyMTkx,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> 
<p>这张架构图能看懂不？百度一搜基本全是这张。</p> 
<pre><code class="prism language-python">Scrapy Engine<span class="token punctuation">(</span>引擎<span class="token punctuation">)</span>：负责Spider、ItemPipeline、Downloader、Scheduler中间的通讯，信号、数据传递等。
Scheduler<span class="token punctuation">(</span>调度器<span class="token punctuation">)</span>：它负责接受引擎发送过来的Request请求，并按照一定的方式进行整理排列，入队，当引擎需要时，交还给引擎。
Downloader（下载器）：负责下载Scrapy Engine<span class="token punctuation">(</span>引擎<span class="token punctuation">)</span>发送的所有Requests请求，并将其获取到的Responses交还给Scrapy Engine<span class="token punctuation">(</span>引擎<span class="token punctuation">)</span>，由引擎交给Spider来处理。
Spider（爬虫）：它负责处理所有Responses<span class="token punctuation">,</span>从中分析提取数据，获取Item字段需要的数据，并将需要跟进的URL提交给引擎，再次进入Scheduler<span class="token punctuation">(</span>调度器<span class="token punctuation">)</span>。
Item Pipeline<span class="token punctuation">(</span>管道<span class="token punctuation">)</span>：它负责处理Spider中获取到的Item，并进行进行后期处理（详细分析、过滤、存储等）的地方。
Downloader Middlewares（下载中间件）：一个可以自定义扩展下载功能的组件。
Spider Middlewares（Spider中间件）：一个可以自定扩展和操作引擎和Spider中间通信的功能组件。
</code></pre> 
<p>注意：当只有调度器中没剩下request的时候，整个项目的运转才会停止。<br> 也就是说，如果某个任务在运行过程中失败了，该网址会被重新访问。</p> 
<p>我在网上看到一段挺形象生动的：</p> 
<pre><code class="prism language-python">！Spider<span class="token punctuation">,</span> 你要处理哪一个网站？

<span class="token number">2</span> Spider：老大要我处理xxxx<span class="token punctuation">.</span>com。

<span class="token number">3</span> 引擎：你把第一个需要处理的URL给我吧。

<span class="token number">4</span> Spider：给你，第一个URL是xxxxxxx<span class="token punctuation">.</span>com。

<span class="token number">5</span> 引擎：Hi！调度器，我这有request请求你帮我排序入队一下。

<span class="token number">6</span> 调度器：好的，正在处理你等一下。

<span class="token number">7</span> 引擎：Hi！调度器，把你处理好的request请求给我。

<span class="token number">8</span> 调度器：给你，这是我处理好的request

<span class="token number">9</span> 引擎：Hi！下载器，你按照老大的下载中间件的设置帮我下载一下这个request请求

<span class="token number">10</span> 下载器：好的！给你，这是下载好的东西。（如果失败：sorry，这个request下载失败了。然后引擎告诉调度器，这个request下载失败了，你记录一下，我们待会儿再下载）

<span class="token number">11</span> 引擎：Hi！Spider，这是下载好的东西，并且已经按照老大的下载中间件处理过了，你自己处理一下（注意！这儿responses默认是交给<span class="token keyword">def</span> parse<span class="token punctuation">(</span><span class="token punctuation">)</span>这个函数处理的）

<span class="token number">12</span> Spider：（处理完毕数据之后对于需要跟进的URL），Hi！引擎，我这里有两个结果，这个是我需要跟进的URL，还有这个是我获取到的Item数据。

<span class="token number">13</span> 引擎：Hi ！管道 我这儿有个item你帮我处理一下！调度器！这是需要跟进URL你帮我处理下。然后从第四步开始循环，直到获取完老大需要全部信息。

<span class="token number">14</span> 管道``调度器：好的，现在就做！
</code></pre> 
<hr> 
<h2><a id="pycharmscrapy_139"></a>pycharm体验scrapy项目</h2> 
<h3><a id="scrapy_140"></a>天才第一步：创建scrapy项目</h3> 
<p>由于pycharm无法直接创建scrapy项目，所以这样操作：<br> 1、在pycharm中打开终端，输入scrapy startproject 项目名（比如说：Test_Scrapy）<br> 弄完之后，刷新两下，会出现这么个东西：<br> <img src="https://img-blog.csdnimg.cn/20201116213535100.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzYyMTkx,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p> 
<p>说明创建成功了。</p> 
<p>下面来简单介绍- - 下各个主要文件的作用:</p> 
<pre><code class="prism language-python">scrapy<span class="token punctuation">.</span>cfg <span class="token punctuation">:</span>项目的配置文件
test_scrapy<span class="token operator">/</span> <span class="token punctuation">:</span>项目的Python模块<span class="token punctuation">,</span>将会从这里引用代码
test_scrapy<span class="token operator">/</span>items<span class="token punctuation">.</span>py <span class="token punctuation">:</span>项目的目标文件
test_scrapy<span class="token operator">/</span>pipelines<span class="token punctuation">.</span>py <span class="token punctuation">:</span>项目的管道文件
test_scrapy<span class="token operator">/</span>settings<span class="token punctuation">.</span>py <span class="token punctuation">:</span>目的设置文件
test_scrapy<span class="token operator">/</span>spiders<span class="token operator">/</span> <span class="token punctuation">:</span>存储爬虫代码目录
</code></pre> 
<hr> 
<h3><a id="items_162"></a>天才第二步：明确目标，构建items</h3> 
<p>我们打算抓取：<code>http://www.itcast.cn/channel/</code> 网站里的所有讲师的姓名、职称和个人信息。</p> 
<pre><code>打开test_scrapy目录下的items.py
Item 定义结构化数据字段，用来保存爬取到的数据，有点像Python中的dict，但是提供了一些额外的保护减少错误。
可以通过创建一个 scrapy.Item 类， 并且定义类型为
scrapy.Field的类属性来定义一个Item（可以理解成类似于ORM的映射关系）。

接下来，创建一个ItcastItem 类，和构建item模型（model）。
</code></pre> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">ItcastItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
	name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    info <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
<hr> 
<h3><a id="_182"></a>制作爬虫</h3> 
<p>进入spiders目录，终端输入命令：</p> 
<pre><code class="prism language-python">scrapy genspider itcast <span class="token string">"itcast.cn"</span>
</code></pre> 
<p>将在test_scrapy/test_scrapy/spider目录下创建一个名为itcast的爬虫，并指定爬取域的范围：</p> 
<p>打开 spider目录里的 itcast.py，默认增加了下列代码:</p> 
<pre><code class="prism language-python"><span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">ItcastSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">"itcast"</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"itcast.cn"</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">(</span>
        <span class="token string">'http://www.itcast.cn/'</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">pass</span>
</code></pre> 
<p>要建立一个Spider， 你必须用scrapy.Spider类创建一个子类，并确定了三个强制的属性 和 一个方法。</p> 
<pre><code class="prism language-python">name <span class="token operator">=</span> <span class="token string">""</span> ：这个爬虫的识别名称，必须是唯一的，在不同的爬虫必须定义不同的名字。

allow_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> 是搜索的域名范围，也就是爬虫的约束区域，规定爬虫只爬取这个域名下的网页，不存在的URL会被忽略。

start_urls <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">)</span> ：爬取的URL元祖<span class="token operator">/</span>列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些urls开始。其他子URL将会从这些起始URL中继承性生成。
</code></pre> 
<p>parse(self, response) ：解析的方法，每个初始URL完成下载后将被调用，调用的时候传入从每一个URL传回的Response对象来作为唯一参数，主要作用如下：</p> 
<pre><code class="prism language-python">负责解析返回的网页数据<span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span>，提取结构化数据<span class="token punctuation">(</span>生成item<span class="token punctuation">)</span>
生成需要下一页的URL请求。
</code></pre> 
<hr> 
<p>将start_urls的值修改为需要爬取的第一个url</p> 
<pre><code class="prism language-python">start_urls <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token string">"http://www.itcast.cn/channel/teacher.shtml"</span><span class="token punctuation">,</span><span class="token punctuation">)</span>
</code></pre> 
<p>修改parse()方法</p> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    filename <span class="token operator">=</span> <span class="token string">"teacher.html"</span>
    <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>write<span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span>
</code></pre> 
<p>然后运行一下看看，在test_scrapy/test_scrapy目录下执行：</p> 
<pre><code class="prism language-python">scrapy crawl itcast
</code></pre> 
<p>是的，就是 itcast，看上面代码，它是 ItcastSpider 类的 name 属性，也就是使用 scrapy genspider命令的唯一爬虫名。</p> 
<p>运行之后，如果打印的日志出现 [scrapy] INFO: Spider closed (finished)，代表执行完成。 之后当前文件夹中就出现了一个 teacher.html 文件，里面就是我们刚刚要爬取的网页的全部源代码信息。</p> 
<hr> 
<h3><a id="_251"></a>取数据</h3> 
<p>爬取整个网页完毕，接下来的就是的取过程了。</p> 
<p>我们之前在test_scrapy/test_scrapy/items.py 里定义了一个ItcastItem类。 这里引入进来</p> 
<pre><code class="prism language-python"> <span class="token keyword">from</span> test_scrapy<span class="token operator">/</span>test_scrapy<span class="token operator">/</span><span class="token punctuation">.</span>items <span class="token keyword">import</span> ItcastItem
</code></pre> 
<p>好，这样写妥妥是要报错的，不这样写又没法子，搞了半天。</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>items <span class="token keyword">import</span> ItcastItem
</code></pre> 
<p>然后将我们得到的数据封装到一个 ItcastItem 对象中，可以保存每个老师的属性：</p> 
<pre><code class="prism language-python"><span class="token keyword">from</span> test_scrapy<span class="token punctuation">.</span>items <span class="token keyword">import</span> ItcastItem

<span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#open("teacher.html","wb").write(response.body).close()</span>

    <span class="token comment"># 存放老师信息的集合</span>
    items <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> each <span class="token keyword">in</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"//div[@class='li_txt']"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 将我们得到的数据封装到一个 `ItcastItem` 对象</span>
        item <span class="token operator">=</span> ItcastItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment">#extract()方法返回的都是unicode字符串</span>
        name <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"h3/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        title <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"h4/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        info <span class="token operator">=</span> each<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">"p/text()"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment">#xpath返回的是包含一个元素的列表</span>
        item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> name<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        item<span class="token punctuation">[</span><span class="token string">'info'</span><span class="token punctuation">]</span> <span class="token operator">=</span> info<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

        items<span class="token punctuation">.</span>append<span class="token punctuation">(</span>item<span class="token punctuation">)</span>

    <span class="token comment"># 直接返回最后数据</span>
    <span class="token keyword">return</span> items
</code></pre> 
<p>scrapy保存信息的最简单的方法主要有四种，-o 输出指定格式的文件，这里我采用的是csv文件</p> 
<p>csv 逗号表达式，可用Excel打开</p> 
<pre><code class="prism language-python">scrapy crawl itcast <span class="token operator">-</span>o teachers<span class="token punctuation">.</span>csv
</code></pre> 
<hr> 
<p>最近都比较忙了些，先把这个框架走通吧，后面还要拓展再拓展，难搞哦。。。</p>
                </div>
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/editerView/markdown_views-10218d227c.css" rel="stylesheet">
                <link href="https://csdnimg.cn/release/blogv2/dist/mdeditor/css/style-6aa8c38f9a.css" rel="stylesheet">
        </div>
    </article>
</body>
</html>
